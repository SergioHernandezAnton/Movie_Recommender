{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "# Read credentials from file\n",
    "with open(\"../Database/credentials.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    username = lines[0].strip()\n",
    "    password = lines[1].strip()\n",
    "    host = lines[2].strip()\n",
    "    database_name = lines[3].strip()\n",
    "\n",
    "# Construct the MongoDB URI\n",
    "uri = f\"mongodb+srv://{username}:{password}@{host}\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "#Connect to database\n",
    "db = client[database_name]\n",
    "\n",
    "#Load movies dataframe\n",
    "movies = db[\"movies\"]\n",
    "movies = list(movies.find())\n",
    "movies = pd.DataFrame(movies)\n",
    "movies = movies.rename(columns = {'_id':'movieId'})\n",
    "\n",
    "#Load ratings dataframe\n",
    "ratings = db[\"ratings\"]\n",
    "ratings = list(ratings.find())\n",
    "ratings = pd.DataFrame(ratings)\n",
    "ratings = ratings.rename(columns = {'_id':'ratingId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings_web dataframe\n",
    "ratings_web = db[\"ratings_web\"]\n",
    "ratings_web = list(ratings_web.find())\n",
    "ratings_web = pd.DataFrame(ratings_web)\n",
    "ratings_web = ratings_web.rename(columns = {'_id':'ratingId'})\n",
    "\n",
    "\n",
    "# Concatenate ratings and ratings_web\n",
    "ratings = pd.concat([ratings, ratings_web], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51372</td>\n",
       "      <td>\"Great Performances\" Cats</td>\n",
       "      <td>['Musical']</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>281280</td>\n",
       "      <td>\"Sr.\"</td>\n",
       "      <td>['Documentary']</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136604</td>\n",
       "      <td>#1 Cheerleader Camp</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221850</td>\n",
       "      <td>#Alive</td>\n",
       "      <td>['Action', 'Horror', 'Thriller']</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221310</td>\n",
       "      <td>#AnneFrank. Parallel Stories</td>\n",
       "      <td>['Documentary']</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                         title                            genres  \\\n",
       "0    51372     \"Great Performances\" Cats                       ['Musical']   \n",
       "1   281280                         \"Sr.\"                   ['Documentary']   \n",
       "2   136604           #1 Cheerleader Camp               ['Comedy', 'Drama']   \n",
       "3   221850                        #Alive  ['Action', 'Horror', 'Thriller']   \n",
       "4   221310  #AnneFrank. Parallel Stories                   ['Documentary']   \n",
       "\n",
       "   year  \n",
       "0  1998  \n",
       "1  2022  \n",
       "2  2010  \n",
       "3  2020  \n",
       "4  2019  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratingId</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>tstamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17227</td>\n",
       "      <td>60834</td>\n",
       "      <td>1608</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:53:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17202</td>\n",
       "      <td>60834</td>\n",
       "      <td>1479</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:53:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17221</td>\n",
       "      <td>60834</td>\n",
       "      <td>1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997-09-17 17:55:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17192</td>\n",
       "      <td>60834</td>\n",
       "      <td>1407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:56:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17196</td>\n",
       "      <td>60834</td>\n",
       "      <td>1422</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:57:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ratingId  userId  movieId  rating               tstamp\n",
       "0    17227   60834     1608     2.0  1997-09-17 17:53:58\n",
       "1    17202   60834     1479     2.0  1997-09-17 17:53:58\n",
       "2    17221   60834     1588     1.0  1997-09-17 17:55:19\n",
       "3    17192   60834     1407     2.0  1997-09-17 17:56:19\n",
       "4    17196   60834     1422     2.0  1997-09-17 17:57:33"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['userId'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 , 9930\n",
      "Number of users with <20 ratings: 606\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of ratings per user\n",
    "ratings_per_user = ratings['userId'].value_counts()\n",
    "\n",
    "# Find the minimum and maximum number of ratings per user\n",
    "min_ratings = ratings_per_user.min()\n",
    "max_ratings = ratings_per_user.max()\n",
    "print(min_ratings, ',', max_ratings)\n",
    "\n",
    "\n",
    "users_with_less_ratings = ratings_per_user[ratings_per_user < 20].shape[0]\n",
    "print(f\"Number of users with <20 ratings: {users_with_less_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a division that ensures that all users appear in training, test and validation. We can not use random split.\n",
    "\n",
    "The split approach will be an 80/20 with minimum thresholds on 10 for training and 10 for test (or at least 5 only for training). Users with less than 20 will be inserted directly to training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1205764, 5), (311343, 5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to split user data into training, validation, and test sets\n",
    "def split_user_data(user_data):\n",
    "    \"\"\"\n",
    "    Splits user data into training, validation, and test sets.\n",
    "    Ensures users have at least `min_ratings` total ratings.\n",
    "    \"\"\"\n",
    "    n = len(user_data)\n",
    "    if 5 <= n < 20:\n",
    "        train = user_data\n",
    "        test = None\n",
    "    elif 20 <= n < 50:\n",
    "        # train = user_data\n",
    "        train = user_data.iloc[-10:]\n",
    "        test = user_data.iloc[:-10]\n",
    "    else:\n",
    "        # Proportional split: 80/20\n",
    "        train_end = int(0.8 * n)\n",
    "        train = user_data.iloc[:train_end]\n",
    "        test = user_data.iloc[train_end:]\n",
    "    return train, test\n",
    "\n",
    "# Apply the splitting across all users\n",
    "train_list, test_list = [], []\n",
    "\n",
    "for user_id, user_data in ratings.groupby(\"userId\"):\n",
    "    user_data = user_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    train, test = split_user_data(user_data)\n",
    "    if train is not None:\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "# Combine splits into dataframes\n",
    "train_data = pd.concat(train_list)\n",
    "test_data = pd.concat(test_list)\n",
    "\n",
    "train_data.shape, test_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the data in matrix format required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in training matrix: 3998\n",
      "Number of items in training matrix: 57079\n",
      "Number of users in test matrix: 3998\n",
      "Number of items in test matrix: 57079\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "# Unified mappings based on the entire ratings dataset\n",
    "user_mapping = {u: i for i, u in enumerate(ratings['userId'].unique())}\n",
    "movie_mapping = {m: i for i, m in enumerate(ratings['movieId'].unique())}\n",
    "\n",
    "# Map user and movie IDs in training and test sets using the mappings\n",
    "train_user_ids = train_data['userId'].map(user_mapping)\n",
    "train_movie_ids = train_data['movieId'].map(movie_mapping)\n",
    "\n",
    "test_user_ids = test_data['userId'].map(user_mapping)\n",
    "test_movie_ids = test_data['movieId'].map(movie_mapping)\n",
    "\n",
    "# Create sparse matrices for training and test sets\n",
    "train_matrix = coo_matrix(\n",
    "    (train_data['rating'], (train_user_ids, train_movie_ids)),\n",
    "    shape=(len(user_mapping), len(movie_mapping))\n",
    ").tocsr()\n",
    "\n",
    "test_matrix = coo_matrix(\n",
    "    (test_data['rating'], (test_user_ids, test_movie_ids)),\n",
    "    shape=(len(user_mapping), len(movie_mapping))\n",
    ").tocsr()\n",
    "\n",
    "# Verify the results\n",
    "print(f\"Number of users in training matrix: {train_matrix.shape[0]}\")\n",
    "print(f\"Number of items in training matrix: {train_matrix.shape[1]}\")\n",
    "print(f\"Number of users in test matrix: {test_matrix.shape[0]}\")\n",
    "print(f\"Number of items in test matrix: {test_matrix.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with zero interactions in training set: 0\n",
      "Number of users with zero interactions in testing set: 606\n"
     ]
    }
   ],
   "source": [
    "# Check for zero interactions\n",
    "train_user_interactions = train_matrix.tocsr().sum(axis=1).A1\n",
    "test_user_interactions = test_matrix.tocsr().sum(axis=1).A1\n",
    "\n",
    "print(f\"Number of users with zero interactions in training set: {(train_user_interactions == 0).sum()}\")\n",
    "print(f\"Number of users with zero interactions in testing set: {(test_user_interactions == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "import implicit\n",
    "import mlflow.pyfunc\n",
    "class ALSModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, als_model, user_item_matrix, user_mapping, movie_mapping, factors, iterations, regularization):\n",
    "        \"\"\"\n",
    "        Custom MLflow wrapper for ALS-based recommendations with ID mapping.\n",
    "        \"\"\"\n",
    "        self.als_model = als_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.user_mapping = user_mapping\n",
    "        self.movie_mapping = movie_mapping\n",
    "        self.reverse_movie_mapping = {v: k for k, v in movie_mapping.items()}  # Reverse mapping for recommendations\n",
    "        self.factors = factors\n",
    "        self.iterations = iterations\n",
    "        self.regularization = regularization\n",
    "\n",
    "    def _get_user_index(self, user_id):\n",
    "        \"\"\"Get the matrix index for a given user ID.\"\"\"\n",
    "        if isinstance(user_id, np.ndarray):\n",
    "            user_id = user_id.item()  # Convert numpy array to a scalar\n",
    "        return self.user_mapping.get(user_id, None)\n",
    "\n",
    "    def _get_movie_indices(self, movie_ids):\n",
    "        \"\"\"Convert movie IDs to matrix column indices.\"\"\"\n",
    "        return [self.movie_mapping[movie_id] for movie_id in movie_ids if movie_id in self.movie_mapping]\n",
    "\n",
    "    def _get_movie_ids(self, movie_indices):\n",
    "        \"\"\"Convert matrix column indices back to movie IDs.\"\"\"\n",
    "        return [self.reverse_movie_mapping[i] for i in movie_indices]\n",
    "\n",
    "    def _reinitialize_and_retrain(self):\n",
    "        \"\"\"Reinitialize the ALS model and retrain with the updated matrix.\"\"\"\n",
    "        self.als_model = implicit.als.AlternatingLeastSquares(\n",
    "            factors=self.factors,\n",
    "            regularization=self.regularization,\n",
    "            iterations=self.iterations,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.als_model.fit(self.user_item_matrix)\n",
    "\n",
    "    def retrain_with_updated_user(self, user_index, movie_ids, ratings):\n",
    "        \"\"\"Update a known user's ratings and retrain.\"\"\"\n",
    "        from scipy.sparse import csr_matrix\n",
    "\n",
    "        # Map movie_ids to matrix column indices\n",
    "        movie_indices = self._get_movie_indices(movie_ids)\n",
    "\n",
    "        # Create a sparse vector for the new ratings\n",
    "        new_ratings = csr_matrix((ratings, ([0] * len(movie_indices), movie_indices)),\n",
    "                                 shape=(1, self.user_item_matrix.shape[1]))\n",
    "\n",
    "        # Combine existing ratings with new ratings\n",
    "        existing_ratings = self.user_item_matrix[user_index]\n",
    "        updated_ratings = existing_ratings + new_ratings\n",
    "\n",
    "        # Replace the user's row in the matrix\n",
    "        self.user_item_matrix[user_index] = updated_ratings\n",
    "\n",
    "        # Reinitialize and retrain the ALS model\n",
    "        self._reinitialize_and_retrain()\n",
    "\n",
    "    def retrain_with_new_user(self, movie_ids, ratings):\n",
    "        \"\"\"Add a new user to the matrix and retrain.\"\"\"\n",
    "        from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "        # Map movie_ids to matrix column indices\n",
    "        movie_indices = self._get_movie_indices(movie_ids)\n",
    "\n",
    "        # Create a sparse vector for the new user ratings\n",
    "        new_user_ratings = csr_matrix((ratings, ([0] * len(movie_indices), movie_indices)),\n",
    "                                      shape=(1, self.user_item_matrix.shape[1]))\n",
    "\n",
    "        # Add the new user to the matrix\n",
    "        self.user_item_matrix = vstack([self.user_item_matrix, new_user_ratings])\n",
    "\n",
    "        # Reinitialize and retrain the ALS model\n",
    "        self._reinitialize_and_retrain()\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        Predict recommendations for a user.\n",
    "\n",
    "        Parameters:\n",
    "        - model_input: Input data in DataFrame or dictionary format.\n",
    "\n",
    "        Returns:\n",
    "        - List of recommended movie IDs.\n",
    "        \"\"\"\n",
    "        # Convert DataFrame input to dictionary\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            model_input = model_input.iloc[0].to_dict()  # Take the first row\n",
    "\n",
    "        # Extract fields from the input\n",
    "        user_id = model_input.get(\"user_id\", None)\n",
    "        n_recommendations = model_input.get(\"n_recommendations\", 10)\n",
    "        movie_ids = model_input.get(\"user_interactions\", None)\n",
    "        ratings = model_input.get(\"ratings\", None)  # New field for user ratings\n",
    "\n",
    "        if user_id is not None:\n",
    "            # Check if user_id exists in the mapping\n",
    "            user_index = self._get_user_index(user_id)\n",
    "            if user_index is not None:\n",
    "                # Known user\n",
    "                if movie_ids is not None and ratings is not None:\n",
    "                    # Update existing user's row and retrain\n",
    "                    self.retrain_with_updated_user(user_index, movie_ids, ratings)\n",
    "\n",
    "                # Recommend for existing user\n",
    "                recommendations, _ = self.als_model.recommend(\n",
    "                    user_index,\n",
    "                    self.user_item_matrix[user_index],\n",
    "                    N=n_recommendations,\n",
    "                )\n",
    "                return self._get_movie_ids(recommendations)\n",
    "\n",
    "        if movie_ids is not None and ratings is not None:\n",
    "            # New user\n",
    "            self.retrain_with_new_user(movie_ids, ratings)\n",
    "\n",
    "            # Get the new user's ID (last row in the matrix)\n",
    "            new_user_index = self.user_item_matrix.shape[0] - 1\n",
    "\n",
    "            # Recommend for the new user\n",
    "            recommendations, _ = self.als_model.recommend(\n",
    "                new_user_index,\n",
    "                self.user_item_matrix[new_user_index],\n",
    "                N=n_recommendations,\n",
    "            )\n",
    "            return self._get_movie_ids(recommendations)\n",
    "\n",
    "        # Raise error if input is invalid\n",
    "        raise ValueError(\"Invalid input: Provide a valid 'user_id' or 'user_interactions' with 'ratings'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have matrices with the ratings of the users, and each of them appear in training, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-12-11_16:41'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M\")  # Fecha actual\n",
    "run_name = f\"ALS Model Run \"+current_date\n",
    "Model_Name = 'ALS retrain'\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f1df5a46da4d039d1d756078c3ed6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13304f409f24b39a2765599b0116ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 16:41:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'ALS retrain 11-12-2024_16.41 0'.\n",
      "2024/12/11 16:41:50 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ALS retrain 11-12-2024_16.41 0, version 1\n",
      "Created version '1' of model 'ALS retrain 11-12-2024_16.41 0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ALS retrain 11-12-2024_16.41 0 registrado con MAP@5: 0.5120\n",
      "🏃 View run ALS Model Run 11-12-2024_16.41 (0) at: http://localhost:5000/#/experiments/0/runs/b901e88023b44110a1a6360b51f8ab5f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e13e77f7f4acab6df416c23b83a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a8ba4c8be34bd7ac1ad299820197bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 16:42:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'ALS retrain 11-12-2024_16.42 1'.\n",
      "2024/12/11 16:42:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ALS retrain 11-12-2024_16.42 1, version 1\n",
      "Created version '1' of model 'ALS retrain 11-12-2024_16.42 1'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ALS retrain 11-12-2024_16.42 1 registrado con MAP@5: 0.5103\n",
      "🏃 View run ALS Model Run 11-12-2024_16.41 (1) at: http://localhost:5000/#/experiments/0/runs/5e50b99332d5485c94481c09b65a224f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60abd7843fb442ab9dbf8595f5e4f865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377443bef832469c86844091579384ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 16:42:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'ALS retrain 11-12-2024_16.42 2'.\n",
      "2024/12/11 16:42:37 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ALS retrain 11-12-2024_16.42 2, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ALS retrain 11-12-2024_16.42 2 registrado con MAP@5: 0.4830\n",
      "🏃 View run ALS Model Run 11-12-2024_16.41 (2) at: http://localhost:5000/#/experiments/0/runs/cdd315e7b0074544911419dcd546c502\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'ALS retrain 11-12-2024_16.42 2'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import joblib\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.evaluation import mean_average_precision_at_k\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "\n",
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%d-%m-%Y_%H.%M\")  # Fecha actual\n",
    "run_name = f\"ALS Model Run \"+current_date\n",
    "Model_Name = 'ALS retrain'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  \n",
    "\n",
    "# Lista de combinaciones de hiperparámetros\n",
    "hyperparameter_grid = [\n",
    "    {\"factors\": 50, \"iterations\": 100, \"regularization\": 0.1},\n",
    "    {\"factors\": 100, \"iterations\": 50, \"regularization\": 0.01},\n",
    "    {\"factors\": 20, \"iterations\": 150, \"regularization\": 0.05}\n",
    "]\n",
    "\n",
    "# Entrenar y registrar múltiples modelos\n",
    "for i, params in enumerate(hyperparameter_grid):\n",
    "    with mlflow.start_run(run_name=run_name+f\" ({i})\"):\n",
    "        # Extraer hiperparámetros\n",
    "        factors = params[\"factors\"]\n",
    "        iterations = params[\"iterations\"]\n",
    "        regularization = params[\"regularization\"]\n",
    "\n",
    "        # Registrar los hiperparámetros en MLflow\n",
    "        mlflow.log_param(\"factors\", factors)\n",
    "        mlflow.log_param(\"iterations\", iterations)\n",
    "        mlflow.log_param(\"regularization\", regularization)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        als_model = AlternatingLeastSquares(\n",
    "            factors=factors,\n",
    "            iterations=iterations,\n",
    "            regularization=regularization,\n",
    "            random_state=42\n",
    "        )\n",
    "        als_model.fit(train_matrix)\n",
    "\n",
    "        # Evaluar el modelo\n",
    "        mapk = mean_average_precision_at_k(als_model, train_matrix, test_matrix, K=5)\n",
    "        mlflow.log_metric(\"MAPK5\", mapk)\n",
    "\n",
    "        # Guardar el modelo localmente\n",
    "        current_date = datetime.datetime.now().strftime(\"%d-%m-%Y_%H.%M\")  # Fecha actual\n",
    "        model_name = Model_Name+f\" {current_date}_{i}\"\n",
    "        model_path = f\"./mlruns/models/{model_name}.pkl\"\n",
    "        joblib.dump(als_model, model_path)\n",
    "\n",
    "        # Registrar el modelo en MLflow usando el wrapper\n",
    "        registered_model_name = Model_Name+f\" {current_date} {i}\"\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            python_model= ALSModelWrapper(als_model, train_matrix, user_mapping, movie_mapping,factors, iterations, regularization),\n",
    "            registered_model_name=registered_model_name\n",
    "        )\n",
    "\n",
    "        print(f\"Modelo {registered_model_name} registrado con MAP@5: {mapk:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell has to be used when added a new model, to format it in order that it can be opened in Docker, as the file path will be app/MLflow, and not the local folder where the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "mlruns_dir = \"mlruns\"\n",
    "# This regex will match any path that starts with file:/// and eventually ends with /Agile/MLflow\n",
    "# It captures 'file:///' followed by any number of characters until '/Agile/MLflow'\n",
    "pattern = re.compile(r\"file:///.*Agile\\\\MLflow\")\n",
    "\n",
    "new_prefix = \"file:///app/MLflow\"\n",
    "\n",
    "for root, dirs, files in os.walk(mlruns_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".yaml\") or file == \"MLmodel\":\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            # Replace any occurrence of paths ending in /Agile/MLflow with /app/MLflow\n",
    "            new_content = pattern.sub(new_prefix, content)\n",
    "\n",
    "            if new_content != content:\n",
    "                print(f\"Updating paths in {file_path}\")\n",
    "                with open(file_path, 'w') as f:\n",
    "                    f.write(new_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
