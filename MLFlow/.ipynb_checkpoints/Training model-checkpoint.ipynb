{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10966ee7-d6bb-4fb0-aa25-bc18ff2a7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "# Read credentials from file\n",
    "with open(\"../Database/credentials.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    username = lines[0].strip()\n",
    "    password = lines[1].strip()\n",
    "    host = lines[2].strip()\n",
    "    database_name = lines[3].strip()\n",
    "\n",
    "# Construct the MongoDB URI\n",
    "uri = f\"mongodb+srv://{username}:{password}@{host}\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "#Connect to database\n",
    "db = client[database_name]\n",
    "\n",
    "#Load movies dataframe\n",
    "movies = db[\"movies\"]\n",
    "movies = list(movies.find())\n",
    "movies = pd.DataFrame(movies)\n",
    "movies = movies.rename(columns = {'_id':'movieId'})\n",
    "\n",
    "#Load ratings dataframe\n",
    "ratings = db[\"ratings\"]\n",
    "ratings = list(ratings.find())\n",
    "ratings = pd.DataFrame(ratings)\n",
    "ratings = ratings.rename(columns = {'_id':'ratingId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "227e40f2-d961-447e-a575-86ec8afb4aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51372</td>\n",
       "      <td>\"Great Performances\" Cats</td>\n",
       "      <td>['Musical']</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>281280</td>\n",
       "      <td>\"Sr.\"</td>\n",
       "      <td>['Documentary']</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136604</td>\n",
       "      <td>#1 Cheerleader Camp</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221850</td>\n",
       "      <td>#Alive</td>\n",
       "      <td>['Action', 'Horror', 'Thriller']</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221310</td>\n",
       "      <td>#AnneFrank. Parallel Stories</td>\n",
       "      <td>['Documentary']</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                         title                            genres  \\\n",
       "0    51372     \"Great Performances\" Cats                       ['Musical']   \n",
       "1   281280                         \"Sr.\"                   ['Documentary']   \n",
       "2   136604           #1 Cheerleader Camp               ['Comedy', 'Drama']   \n",
       "3   221850                        #Alive  ['Action', 'Horror', 'Thriller']   \n",
       "4   221310  #AnneFrank. Parallel Stories                   ['Documentary']   \n",
       "\n",
       "   year  \n",
       "0  1998  \n",
       "1  2022  \n",
       "2  2010  \n",
       "3  2020  \n",
       "4  2019  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c28765-b145-462d-932c-febedbb8c265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratingId</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>tstamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17227</td>\n",
       "      <td>60834</td>\n",
       "      <td>1608</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:53:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17202</td>\n",
       "      <td>60834</td>\n",
       "      <td>1479</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:53:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17221</td>\n",
       "      <td>60834</td>\n",
       "      <td>1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997-09-17 17:55:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17192</td>\n",
       "      <td>60834</td>\n",
       "      <td>1407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:56:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17196</td>\n",
       "      <td>60834</td>\n",
       "      <td>1422</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997-09-17 17:57:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratingId  userId  movieId  rating               tstamp\n",
       "0     17227   60834     1608     2.0  1997-09-17 17:53:58\n",
       "1     17202   60834     1479     2.0  1997-09-17 17:53:58\n",
       "2     17221   60834     1588     1.0  1997-09-17 17:55:19\n",
       "3     17192   60834     1407     2.0  1997-09-17 17:56:19\n",
       "4     17196   60834     1422     2.0  1997-09-17 17:57:33"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66cc543b-6a79-4b89-9870-8159eacc722e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42170"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['userId'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b07aa54-d1a9-47be-95ed-40572e52ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 , 9930\n",
      "Number of users with <20 ratings: 601\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of ratings per user\n",
    "ratings_per_user = ratings['userId'].value_counts()\n",
    "\n",
    "# Find the minimum and maximum number of ratings per user\n",
    "min_ratings = ratings_per_user.min()\n",
    "max_ratings = ratings_per_user.max()\n",
    "print(min_ratings, ',', max_ratings)\n",
    "\n",
    "\n",
    "users_with_less_ratings = ratings_per_user[ratings_per_user < 20].shape[0]\n",
    "print(f\"Number of users with <20 ratings: {users_with_less_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8959f-5670-4939-bf54-9cde8516e8f3",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c0295-db0f-4cd4-902a-fde56ec15863",
   "metadata": {},
   "source": [
    "### Preparing data division"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d394b-c681-461b-829c-8ed42577f007",
   "metadata": {},
   "source": [
    "We want a division that ensures that all users appear in training, test and validation. We can not use random split.\n",
    "\n",
    "The split approach will be an 80/20 with minimum thresholds on 10 for training and 10 for test (or at least 5 only for training). Users with less than 20 will be inserted directly to training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de217df6-1364-4545-90a3-e084c73fede5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1205706, 5), (311343, 5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to split user data into training, validation, and test sets\n",
    "def split_user_data(user_data):\n",
    "    \"\"\"\n",
    "    Splits user data into training, validation, and test sets.\n",
    "    Ensures users have at least `min_ratings` total ratings.\n",
    "    \"\"\"\n",
    "    n = len(user_data)\n",
    "    if 5 <= n < 20:\n",
    "        train = user_data\n",
    "        test = None\n",
    "    elif 20 <= n < 50:\n",
    "        # train = user_data\n",
    "        train = user_data.iloc[-10:]\n",
    "        test = user_data.iloc[:-10]\n",
    "    else:\n",
    "        # Proportional split: 80/20\n",
    "        train_end = int(0.8 * n)\n",
    "        train = user_data.iloc[:train_end]\n",
    "        test = user_data.iloc[train_end:]\n",
    "    return train, test\n",
    "\n",
    "# Apply the splitting across all users\n",
    "train_list, test_list = [], []\n",
    "\n",
    "for user_id, user_data in ratings.groupby(\"userId\"):\n",
    "    user_data = user_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    train, test = split_user_data(user_data)\n",
    "    if train is not None:\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "# Combine splits into dataframes\n",
    "train_data = pd.concat(train_list)\n",
    "test_data = pd.concat(test_list)\n",
    "\n",
    "train_data.shape, test_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586176b-4717-4287-baa3-4f69c6820f32",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add97e3-4232-4959-b70a-90574f585806",
   "metadata": {},
   "source": [
    "We prepare the data in matrix format required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b222fe27-51b3-46ac-808f-186c12095029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in training matrix: 3993\n",
      "Number of items in training matrix: 57079\n",
      "Number of users in test matrix: 3993\n",
      "Number of items in test matrix: 57079\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "# Unified mappings based on the entire ratings dataset\n",
    "user_mapping = {u: i for i, u in enumerate(ratings['userId'].unique())}\n",
    "movie_mapping = {m: i for i, m in enumerate(ratings['movieId'].unique())}\n",
    "\n",
    "# Map user and movie IDs in training and test sets using the mappings\n",
    "train_user_ids = train_data['userId'].map(user_mapping)\n",
    "train_movie_ids = train_data['movieId'].map(movie_mapping)\n",
    "\n",
    "test_user_ids = test_data['userId'].map(user_mapping)\n",
    "test_movie_ids = test_data['movieId'].map(movie_mapping)\n",
    "\n",
    "# Create sparse matrices for training and test sets\n",
    "train_matrix = coo_matrix(\n",
    "    (train_data['rating'], (train_user_ids, train_movie_ids)),\n",
    "    shape=(len(user_mapping), len(movie_mapping))\n",
    ").tocsr()\n",
    "\n",
    "test_matrix = coo_matrix(\n",
    "    (test_data['rating'], (test_user_ids, test_movie_ids)),\n",
    "    shape=(len(user_mapping), len(movie_mapping))\n",
    ").tocsr()\n",
    "\n",
    "# Verify the results\n",
    "print(f\"Number of users in training matrix: {train_matrix.shape[0]}\")\n",
    "print(f\"Number of items in training matrix: {train_matrix.shape[1]}\")\n",
    "print(f\"Number of users in test matrix: {test_matrix.shape[0]}\")\n",
    "print(f\"Number of items in test matrix: {test_matrix.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cded5632-33a5-4f46-8daa-6dbaef619742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with zero interactions in training set: 0\n",
      "Number of users with zero interactions in testing set: 601\n"
     ]
    }
   ],
   "source": [
    "# Check for zero interactions\n",
    "train_user_interactions = train_matrix.tocsr().sum(axis=1).A1\n",
    "test_user_interactions = test_matrix.tocsr().sum(axis=1).A1\n",
    "\n",
    "print(f\"Number of users with zero interactions in training set: {(train_user_interactions == 0).sum()}\")\n",
    "print(f\"Number of users with zero interactions in testing set: {(test_user_interactions == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e0272df-d43b-4a9e-bb30-fc29011339d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "import implicit\n",
    "import mlflow.pyfunc\n",
    "class ALSModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, als_model, user_item_matrix, user_mapping, movie_mapping, factors, iterations, regularization):\n",
    "        \"\"\"\n",
    "        Custom MLflow wrapper for ALS-based recommendations with ID mapping.\n",
    "        \"\"\"\n",
    "        self.als_model = als_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.user_mapping = user_mapping\n",
    "        self.movie_mapping = movie_mapping\n",
    "        self.reverse_movie_mapping = {v: k for k, v in movie_mapping.items()}  # Reverse mapping for recommendations\n",
    "        self.factors = factors\n",
    "        self.iterations = iterations\n",
    "        self.regularization = regularization\n",
    "\n",
    "    def _get_user_index(self, user_id):\n",
    "        \"\"\"Get the matrix index for a given user ID.\"\"\"\n",
    "        if isinstance(user_id, np.ndarray):\n",
    "            user_id = user_id.item()  # Convert numpy array to a scalar\n",
    "        return self.user_mapping.get(user_id, None)\n",
    "\n",
    "    def _get_movie_indices(self, movie_ids):\n",
    "        \"\"\"Convert movie IDs to matrix column indices.\"\"\"\n",
    "        return [self.movie_mapping[movie_id] for movie_id in movie_ids if movie_id in self.movie_mapping]\n",
    "\n",
    "    def _get_movie_ids(self, movie_indices):\n",
    "        \"\"\"Convert matrix column indices back to movie IDs.\"\"\"\n",
    "        return [self.reverse_movie_mapping[i] for i in movie_indices]\n",
    "\n",
    "    def _reinitialize_and_retrain(self):\n",
    "        \"\"\"Reinitialize the ALS model and retrain with the updated matrix.\"\"\"\n",
    "        self.als_model = implicit.als.AlternatingLeastSquares(\n",
    "            factors=self.factors,\n",
    "            regularization=self.regularization,\n",
    "            iterations=self.iterations,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.als_model.fit(self.user_item_matrix)\n",
    "\n",
    "    def retrain_with_updated_user(self, user_index, movie_ids, ratings):\n",
    "        \"\"\"Update a known user's ratings and retrain.\"\"\"\n",
    "        from scipy.sparse import csr_matrix\n",
    "\n",
    "        # Map movie_ids to matrix column indices\n",
    "        movie_indices = self._get_movie_indices(movie_ids)\n",
    "\n",
    "        # Create a sparse vector for the new ratings\n",
    "        new_ratings = csr_matrix((ratings, ([0] * len(movie_indices), movie_indices)),\n",
    "                                 shape=(1, self.user_item_matrix.shape[1]))\n",
    "\n",
    "        # Combine existing ratings with new ratings\n",
    "        existing_ratings = self.user_item_matrix[user_index]\n",
    "        updated_ratings = existing_ratings + new_ratings\n",
    "\n",
    "        # Replace the user's row in the matrix\n",
    "        self.user_item_matrix[user_index] = updated_ratings\n",
    "\n",
    "        # Reinitialize and retrain the ALS model\n",
    "        self._reinitialize_and_retrain()\n",
    "\n",
    "    def retrain_with_new_user(self, movie_ids, ratings):\n",
    "        \"\"\"Add a new user to the matrix and retrain.\"\"\"\n",
    "        from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "        # Map movie_ids to matrix column indices\n",
    "        movie_indices = self._get_movie_indices(movie_ids)\n",
    "\n",
    "        # Create a sparse vector for the new user ratings\n",
    "        new_user_ratings = csr_matrix((ratings, ([0] * len(movie_indices), movie_indices)),\n",
    "                                      shape=(1, self.user_item_matrix.shape[1]))\n",
    "\n",
    "        # Add the new user to the matrix\n",
    "        self.user_item_matrix = vstack([self.user_item_matrix, new_user_ratings])\n",
    "\n",
    "        # Reinitialize and retrain the ALS model\n",
    "        self._reinitialize_and_retrain()\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        Predict recommendations for a user.\n",
    "\n",
    "        Parameters:\n",
    "        - model_input: Input data in DataFrame or dictionary format.\n",
    "\n",
    "        Returns:\n",
    "        - List of recommended movie IDs.\n",
    "        \"\"\"\n",
    "        # Convert DataFrame input to dictionary\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            model_input = model_input.iloc[0].to_dict()  # Take the first row\n",
    "\n",
    "        # Extract fields from the input\n",
    "        user_id = model_input.get(\"user_id\", None)\n",
    "        n_recommendations = model_input.get(\"n_recommendations\", 10)\n",
    "        movie_ids = model_input.get(\"user_interactions\", None)\n",
    "        ratings = model_input.get(\"ratings\", None)  # New field for user ratings\n",
    "\n",
    "        if user_id is not None:\n",
    "            # Check if user_id exists in the mapping\n",
    "            user_index = self._get_user_index(user_id)\n",
    "            if user_index is not None:\n",
    "                # Known user\n",
    "                if movie_ids is not None and ratings is not None:\n",
    "                    # Update existing user's row and retrain\n",
    "                    self.retrain_with_updated_user(user_index, movie_ids, ratings)\n",
    "\n",
    "                # Recommend for existing user\n",
    "                recommendations, _ = self.als_model.recommend(\n",
    "                    user_index,\n",
    "                    self.user_item_matrix[user_index],\n",
    "                    N=n_recommendations,\n",
    "                )\n",
    "                return self._get_movie_ids(recommendations)\n",
    "\n",
    "        if movie_ids is not None and ratings is not None:\n",
    "            # New user\n",
    "            self.retrain_with_new_user(movie_ids, ratings)\n",
    "\n",
    "            # Get the new user's ID (last row in the matrix)\n",
    "            new_user_index = self.user_item_matrix.shape[0] - 1\n",
    "\n",
    "            # Recommend for the new user\n",
    "            recommendations, _ = self.als_model.recommend(\n",
    "                new_user_index,\n",
    "                self.user_item_matrix[new_user_index],\n",
    "                N=n_recommendations,\n",
    "            )\n",
    "            return self._get_movie_ids(recommendations)\n",
    "\n",
    "        # Raise error if input is invalid\n",
    "        raise ValueError(\"Invalid input: Provide a valid 'user_id' or 'user_interactions' with 'ratings'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3811606-dd38-45cd-a593-6b4f73bd1561",
   "metadata": {},
   "source": [
    "Now we have matrices with the ratings of the users, and each of them appear in training, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69b22cb8-a4bc-4d2b-a7b3-6b4dbbf60291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e124e163a44389b57fb0d27d12ee95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb0fafa6a8c467a9ca23f68a114a234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run ALS Model Run 0 at: http://localhost:5000/#/experiments/0/runs/2386c6618c334e4b8a5f8f6cea27d7a9\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Models/als_model_0.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Guardar el modelo localmente\u001b[39;00m\n\u001b[0;32m     45\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Models/als_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Usar una ruta válida dentro del contenedor\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mals_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Registrar el modelo en MLflow usando el wrapper\u001b[39;00m\n\u001b[0;32m     49\u001b[0m registered_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALS_Recommender_Model_with_Predict_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Agile\\lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Models/als_model_0.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "import mlflow.pyfunc\n",
    "import joblib\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.evaluation import mean_average_precision_at_k\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  \n",
    "\n",
    "# Lista de combinaciones de hiperparámetros\n",
    "hyperparameter_grid = [\n",
    "    {\"factors\": 50, \"iterations\": 100, \"regularization\": 0.1},\n",
    "    {\"factors\": 100, \"iterations\": 50, \"regularization\": 0.01},\n",
    "    {\"factors\": 20, \"iterations\": 150, \"regularization\": 0.05}\n",
    "]\n",
    "\n",
    "# Entrenar y registrar múltiples modelos\n",
    "for i, params in enumerate(hyperparameter_grid):\n",
    "    with mlflow.start_run(run_name=f\"ALS Model Run {i}\"):\n",
    "        # Extraer hiperparámetros\n",
    "        factors = params[\"factors\"]\n",
    "        iterations = params[\"iterations\"]\n",
    "        regularization = params[\"regularization\"]\n",
    "\n",
    "        # Registrar los hiperparámetros en MLflow\n",
    "        mlflow.log_param(\"factors\", factors)\n",
    "        mlflow.log_param(\"iterations\", iterations)\n",
    "        mlflow.log_param(\"regularization\", regularization)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        als_model = AlternatingLeastSquares(\n",
    "            factors=factors,\n",
    "            iterations=iterations,\n",
    "            regularization=regularization,\n",
    "            random_state=42\n",
    "        )\n",
    "        als_model.fit(train_matrix)\n",
    "\n",
    "        # Evaluar el modelo\n",
    "        mapk = mean_average_precision_at_k(als_model, train_matrix, test_matrix, K=5)\n",
    "        mlflow.log_metric(\"MAPK5\", mapk)\n",
    "\n",
    "        # Guardar el modelo localmente\n",
    "        model_path = f\"./models/als_model_{i}.pkl\"  # Usar una ruta válida dentro del contenedor\n",
    "        joblib.dump(als_model, model_path)\n",
    "\n",
    "        # Registrar el modelo en MLflow usando el wrapper\n",
    "        registered_model_name = f\"ALS_Recommender_Model_with_Predict_{i}\"\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            python_model= ALSModelWrapper(als_model, train_matrix, user_mapping, movie_mapping,factors, iterations, regularization),\n",
    "            registered_model_name=registered_model_name\n",
    "        )\n",
    "\n",
    "        print(f\"Modelo {registered_model_name} registrado con MAP@5: {mapk:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68276de7-a941-4843-9212-37926de965b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
